{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "import attr\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.set_visible_devices([], 'GPU') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from filterflow.base import State\n",
    "from filterflow.resampling.standard import SystematicResampler, StratifiedResampler, MultinomialResampler\n",
    "from filterflow.resampling.base import NoResampling\n",
    "from filterflow.resampling.differentiable import RegularisedTransform, CorrectedRegularizedTransform\n",
    "from filterflow.resampling.differentiable.optimized import OptimizedPointCloud\n",
    "from filterflow.resampling.differentiable.optimizer.sgd import SGD\n",
    "from filterflow.resampling.differentiable.ricatti.solver import PetkovSolver\n",
    "from filterflow.resampling.differentiable.loss.sliced_wasserstein.swd import SlicedWassersteinDistance\n",
    "from filterflow.resampling.differentiable.loss.regularized import SinkhornLoss\n",
    "from filterflow.resampling.differentiable.loss.sliced_wasserstein.utils import sqeuclidean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook aims to demonstrate the differentiability issue encountered at resampling time. To do this we will compare functionals of the point cloud whilst changing a parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "B = 1\n",
    "N = 50\n",
    "D = 10\n",
    "\n",
    "x = tf.random.normal([B, N, D], 0., 1.)\n",
    "y = tf.zeros(D)\n",
    "\n",
    "weights = tf.random.uniform([B, N], 0., 1.)\n",
    "weights = weights / tf.reduce_sum(weights, axis=1, keepdims=True)\n",
    "log_weights = tf.zeros([B, N]) - math.log(N)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def log_likelihood(state, observation, resampler, seed=666):\n",
    "    tf.random.set_seed(seed)\n",
    "    rv = tfp.distributions.MultivariateNormalDiag(tf.zeros(D), tf.ones(D))\n",
    "    flags = tf.constant([True])\n",
    "    log_prob = rv.log_prob(observation-state.particles)\n",
    "    log_weights = log_prob - tf.reduce_logsumexp(log_prob, 1, keepdims=True)\n",
    "    state = attr.evolve(state, log_weights=log_weights, weights=tf.math.exp(log_weights))\n",
    "    state = resampler.apply(state, flags)\n",
    "    log_prob = rv.log_prob(observation-state.particles) + state.log_weights\n",
    "    return tf.reduce_logsumexp(log_prob)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "linspace = np.linspace(-0.5, 0.5, 150).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not decorate this. seed is being set\n",
    "def get_data(linspace, resampler, x, y):\n",
    "    res = []\n",
    "    grads = []\n",
    "    for z_val in tqdm.tqdm(linspace):\n",
    "        z = z_val + tf.zeros(D)\n",
    "        tf.random.set_seed(666)\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(z)\n",
    "            state = State(x + z, log_weights, tf.math.exp(log_weights), tf.constant([0.]))\n",
    "            ll = log_likelihood(state, y, resampler)\n",
    "        ll_grad = tape.gradient(ll, z)\n",
    "        res.append(ll.numpy().sum())\n",
    "        grads.append(ll_grad.numpy().sum())\n",
    "    return res, grads\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "systematic = SystematicResampler()\n",
    "multinomial = MultinomialResampler()\n",
    "stratified = StratifiedResampler()\n",
    "no_resampling = NoResampling()\n",
    "\n",
    "epsilon = tf.constant(0.1)\n",
    "scaling = tf.constant(0.5)\n",
    "convergence_threshold = tf.constant(1e-3)\n",
    "max_iter = tf.constant(500)\n",
    "\n",
    "regularized = RegularisedTransform(epsilon, scaling, max_iter, convergence_threshold)\n",
    "\n",
    "step_size = tf.constant(0.25)\n",
    "horizon = tf.constant(5.)\n",
    "threshold = tf.constant(1e-2)\n",
    "\n",
    "solver = PetkovSolver(n_iter=tf.constant(30))\n",
    "corrected_no_grad = CorrectedRegularizedTransform(epsilon, scaling, max_iter, convergence_threshold, ricatti_solver=solver, propagate_correction_gradient=False)\n",
    "corrected = CorrectedRegularizedTransform(epsilon, scaling, max_iter, convergence_threshold, ricatti_solver=solver, propagate_correction_gradient=True)\n",
    "\n",
    "sinkhorn_loss = SinkhornLoss(epsilon, symmetric=True, scaling=scaling, max_iter=tf.constant(100), convergence_threshold=convergence_threshold)\n",
    "sinkhorn_optimizer = SGD(sinkhorn_loss, 50., 50, 0.95)\n",
    "sinkhorn_optimized_cloud = OptimizedPointCloud(sinkhorn_optimizer, regularized)\n",
    "\n",
    "sliced_loss = SlicedWassersteinDistance(10, sqeuclidean)\n",
    "sliced_optimizer = SGD(sliced_loss, 1., 20, 0.75)\n",
    "sliced_optimized_cloud = OptimizedPointCloud(sliced_optimizer, regularized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/150 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\linalg\\linear_operator_diag.py:166: calling LinearOperator.__init__ (from tensorflow.python.ops.linalg.linear_operator) with graph_parents is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Do not pass `graph_parents`.  They will  no longer be used.\n",
      "loss [0.329190254]\n",
      "0.0161165837\n",
      "loss [0.225150913]\n",
      "0.00572164729\n",
      "loss [0.212497786]\n",
      "0.00145895965\n",
      "loss [0.211328596]\n",
      "0.00125881936\n",
      "loss [0.210395068]\n",
      "0.00171431154\n",
      "loss [0.209821343]\n",
      "0.00139287626\n",
      "loss [0.209500343]\n",
      "0.000550209545\n",
      "loss [0.209342316]\n",
      "0.000309508061\n",
      "loss [0.209246486]\n",
      "0.000342474552\n",
      "loss [0.209162921]\n",
      "0.000414597569\n",
      "loss [0.209064573]\n",
      "0.000552246231\n",
      "loss [0.208922938]\n",
      "0.000793768966\n",
      "loss [0.208697632]\n",
      "0.00115333148\n",
      "loss [0.208362475]\n",
      "0.00145966606\n",
      "loss [0.208000809]\n",
      "0.00135326479\n",
      "loss [0.207761198]\n",
      "0.000925853499\n",
      "loss [0.207650214]\n",
      "0.000553482852\n",
      "loss [0.207602859]\n",
      "0.000324870634\n",
      "loss [0.207581252]\n",
      "0.000195009285\n",
      "loss [0.207570061]\n",
      "0.000124006649\n",
      "loss [0.207563341]\n",
      "8.71028751e-05\n",
      "loss [0.207558811]\n",
      "6.24395907e-05\n",
      "loss [0.207554981]\n",
      "4.97037545e-05\n",
      "loss [0.207551703]\n",
      "4.07951884e-05\n",
      "loss [0.207548559]\n",
      "3.73837538e-05\n",
      "loss [0.207545757]\n",
      "3.66657041e-05\n",
      "loss [0.207543075]\n",
      "3.59762926e-05\n",
      "loss [0.207540333]\n",
      "3.53124924e-05\n",
      "loss [0.207537636]\n",
      "3.46787274e-05\n",
      "loss [0.207534835]\n",
      "3.40715051e-05\n",
      "loss [0.207532257]\n",
      "3.50000337e-05\n",
      "loss [0.207529724]\n",
      "3.74256633e-05\n",
      "loss [0.207527146]\n",
      "4.00692225e-05\n",
      "loss [0.207524449]\n",
      "4.2937696e-05\n",
      "loss [0.207521945]\n",
      "4.6083238e-05\n",
      "loss [0.207519189]\n",
      "4.94788401e-05\n",
      "loss [0.207516596]\n",
      "5.31906262e-05\n",
      "loss [0.207513839]\n",
      "5.71855344e-05\n",
      "loss [0.207511023]\n",
      "6.15385361e-05\n",
      "loss [0.207508266]\n",
      "6.62286766e-05\n",
      "loss [0.207505405]\n",
      "7.1331393e-05\n",
      "loss [0.207502395]\n",
      "7.68299215e-05\n",
      "loss [0.207499489]\n",
      "8.27675685e-05\n",
      "loss [0.207496494]\n",
      "8.91722739e-05\n",
      "loss [0.207493424]\n",
      "9.60789621e-05\n",
      "loss [0.207490295]\n",
      "0.000103523023\n",
      "loss [0.207486928]\n",
      "0.000111557543\n",
      "loss [0.207483649]\n",
      "0.000120188575\n",
      "loss [0.207480237]\n",
      "0.000129470602\n",
      "loss [0.207476825]\n",
      "0.000139434822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▌                                                                                 | 1/150 [00:07<18:36,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss [0.326616228]\n",
      "0.0159585867\n",
      "loss [0.222948432]\n",
      "0.00593814533\n",
      "loss [0.212132573]\n",
      "0.00153439678\n",
      "loss [0.210941717]\n",
      "0.00158034312\n",
      "loss [0.209898725]\n",
      "0.0019737347\n",
      "loss [0.209324956]\n",
      "0.000388602493\n",
      "loss [0.209225804]\n",
      "0.000385869294\n",
      "loss [0.209170327]\n",
      "0.000388691202\n",
      "loss [0.209124044]\n",
      "0.000356021337\n",
      "loss [0.209083065]\n",
      "0.000305550173\n",
      "loss [0.209044352]\n",
      "0.000253140926\n",
      "loss [0.209003359]\n",
      "0.000218093395\n",
      "loss [0.208950222]\n",
      "0.000381959137\n",
      "loss [0.208859757]\n",
      "0.000793555519\n",
      "loss [0.208636343]\n",
      "0.00190612208\n",
      "loss [0.207938403]\n",
      "0.00324318279\n",
      "loss [0.206851]\n",
      "0.00230120495\n",
      "loss [0.206365272]\n",
      "0.00130687188\n",
      "loss [0.206194401]\n",
      "0.000763300806\n",
      "loss [0.206130296]\n",
      "0.000461468473\n",
      "loss [0.206106246]\n",
      "0.000288170762\n",
      "loss [0.206096396]\n",
      "0.000185397454\n",
      "loss [0.206093609]\n",
      "0.000122600235\n",
      "loss [0.206092775]\n",
      "8.31531361e-05\n",
      "loss [0.206093505]\n",
      "5.7737343e-05\n",
      "loss [0.206093788]\n",
      "4.58396971e-05\n",
      "loss [0.206094533]\n",
      "4.3834094e-05\n",
      "loss [0.206094906]\n",
      "4.20091674e-05\n",
      "loss [0.206095368]\n",
      "4.03451268e-05\n",
      "loss [0.206095487]\n",
      "3.8828468e-05\n",
      "loss [0.206095666]\n",
      "3.74433585e-05\n",
      "loss [0.20609577]\n",
      "3.61683778e-05\n",
      "loss [0.206095815]\n",
      "3.50058544e-05\n",
      "loss [0.206095755]\n",
      "3.39332037e-05\n",
      "loss [0.206095546]\n",
      "3.29480972e-05\n",
      "loss [0.206095487]\n",
      "3.20416875e-05\n",
      "loss [0.206095248]\n",
      "3.11995391e-05\n",
      "loss [0.206095129]\n",
      "3.04253772e-05\n",
      "loss [0.206095]\n",
      "2.97056977e-05\n",
      "loss [0.206094742]\n",
      "2.9042596e-05\n",
      "loss [0.206094638]\n",
      "2.84246635e-05\n",
      "loss [0.206094503]\n",
      "2.80543463e-05\n",
      "loss [0.206094369]\n",
      "2.77237268e-05\n",
      "loss [0.206094027]\n",
      "2.74080085e-05\n",
      "loss [0.206094027]\n",
      "2.71108e-05\n",
      "loss [0.206093818]\n",
      "2.68328e-05\n",
      "loss [0.206093758]\n",
      "2.65701674e-05\n",
      "loss [0.206093401]\n",
      "2.63233669e-05\n",
      "loss [0.206093311]\n",
      "2.60877423e-05\n",
      "loss [0.206093237]\n",
      "2.58702785e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|█                                                                                 | 2/150 [00:11<15:33,  6.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss [0.323320031]\n",
      "0.0156765636\n",
      "loss [0.203639567]\n",
      "0.00535042\n",
      "loss [0.189563513]\n",
      "0.00251387479\n",
      "loss [0.187036961]\n",
      "0.00136436895\n",
      "loss [0.186484069]\n",
      "0.000426042825\n",
      "loss [0.186361477]\n",
      "0.000351348892\n",
      "loss [0.186287493]\n",
      "0.000275040045\n",
      "loss [0.186231077]\n",
      "0.0002106959\n",
      "loss [0.186170369]\n",
      "0.000345557695\n",
      "loss [0.186073482]\n",
      "0.000767429359\n",
      "loss [0.185809731]\n",
      "0.00208260212\n",
      "loss [0.184852749]\n",
      "0.00330899656\n",
      "loss [0.183668539]\n",
      "0.00173340272\n",
      "loss [0.183366865]\n",
      "0.00186791271\n",
      "loss [0.183016986]\n",
      "0.00322722644\n",
      "loss [0.181934416]\n",
      "0.00209486857\n",
      "loss [0.181387872]\n",
      "0.00156252657\n",
      "loss [0.181218565]\n",
      "0.00147142354\n",
      "loss [0.181130692]\n",
      "0.00211894698\n",
      "loss [0.181043252]\n",
      "0.00157474168\n",
      "loss [0.181025207]\n",
      "0.000996947289\n",
      "loss [0.181016907]\n",
      "0.000649705529\n",
      "loss [0.181013525]\n",
      "0.000496985391\n",
      "loss [0.181017756]\n",
      "0.000367961824\n",
      "loss [0.181024864]\n",
      "0.000274132937\n",
      "loss [0.18103157]\n",
      "0.000207652018\n",
      "loss [0.181037053]\n",
      "0.000160236377\n",
      "loss [0.181041181]\n",
      "0.000125966966\n",
      "loss [0.181044579]\n",
      "0.000100774545\n",
      "loss [0.181047082]\n",
      "8.19452107e-05\n",
      "loss [0.18104893]\n",
      "6.76717609e-05\n",
      "loss [0.181050152]\n",
      "5.66728413e-05\n",
      "loss [0.181051075]\n",
      "4.80674207e-05\n",
      "loss [0.181051761]\n",
      "4.12743539e-05\n",
      "loss [0.181052253]\n",
      "3.58372927e-05\n",
      "loss [0.181052759]\n",
      "3.1423464e-05\n",
      "loss [0.181052953]\n",
      "2.78186053e-05\n",
      "loss [0.181053072]\n",
      "2.48402357e-05\n",
      "loss [0.1810534]\n",
      "2.23517418e-05\n",
      "loss [0.181053489]\n",
      "2.1693937e-05\n",
      "loss [0.181053579]\n",
      "2.14463798e-05\n",
      "loss [0.181053549]\n",
      "2.12144223e-05\n",
      "loss [0.181053594]\n",
      "2.10060971e-05\n",
      "loss [0.181053549]\n",
      "2.08015554e-05\n",
      "loss [0.181053564]\n",
      "2.06024852e-05\n",
      "loss [0.181053489]\n",
      "2.04223907e-05\n",
      "loss [0.181053594]\n",
      "2.02622032e-05\n",
      "loss [0.181053549]\n",
      "2.01041112e-05\n",
      "loss [0.181053489]\n",
      "1.99536444e-05\n",
      "loss [0.181053519]\n",
      "1.98051566e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▋                                                                                | 3/150 [00:14<13:23,  5.46s/it]"
     ]
    }
   ],
   "source": [
    "# no_resampling_data, no_resampling_grad = get_data(linspace, no_resampling, x, y)\n",
    "# systematic_data, systematic_grad = get_data(linspace, systematic, x, y)\n",
    "# multinomial_data, multinomial_grad = get_data(linspace, multinomial, x, y)\n",
    "# stratified_data, stratified_grad = get_data(linspace, stratified, x, y)\n",
    "\n",
    "# regularized_data, regularized_grad = get_data(linspace, regularized, x, y)\n",
    "# corrected_no_grad_data, corrected_no_grad_grad = get_data(linspace, corrected_no_grad, x, y)\n",
    "# corrected_data, corrected_grad = get_data(linspace, corrected, x, y)\n",
    "# sliced_optimized_data, sliced_optimized_grad = get_data(linspace, sliced_optimized_cloud, x, y)\n",
    "sinkhorn_optimized_data, sinkhorn_optimized_grad = get_data(linspace, sinkhorn_optimized_cloud, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=2, figsize=(15, 5), sharex=True, sharey=True)\n",
    "axes[0].plot(linspace, no_resampling_data, label='no resampling', linestyle='--', color='k')\n",
    "axes[1].plot(linspace, no_resampling_data, label='no resampling', linestyle='--', color='k')\n",
    "axes[0].step(linspace, systematic_data, label='systematic', alpha=0.75)\n",
    "axes[0].step(linspace, multinomial_data, label='multinomial', alpha=0.75)\n",
    "axes[0].step(linspace, stratified_data, label='stratified', alpha=0.75)\n",
    "# axes[1].plot(linspace, regularized_data, label='regularized')\n",
    "axes[1].plot(linspace, corrected_data, label='corrected')\n",
    "axes[1].plot(linspace, corrected_no_grad_data, label='corrected_no_grad')\n",
    "axes[1].plot(linspace, optimized_data, label='optimized_data')\n",
    "_ = axes[0].legend(), axes[1].legend()\n",
    "fig.savefig(os.path.join('./charts/', 'differentiability_illustration_likelihood.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=2, figsize=(15, 5), sharex=True, sharey=False)\n",
    "axes[0].step(linspace, no_resampling_grad, label='no resampling', linestyle='--', color='k')\n",
    "axes[1].step(linspace, no_resampling_grad, label='no resampling', linestyle='--', color='k')\n",
    "axes[0].step(linspace, systematic_grad, label='systematic', alpha=0.75)\n",
    "axes[0].step(linspace, multinomial_grad, label='multinomial', alpha=0.75)\n",
    "axes[0].step(linspace, stratified_grad, label='stratified', alpha=0.75)\n",
    "# axes[1].plot(linspace, regularized_grad, label='regularized')\n",
    "axes[1].plot(linspace, corrected_grad, label='corrected')\n",
    "axes[1].plot(linspace, corrected_no_grad_grad, label='corrected_no_grad')\n",
    "axes[1].plot(linspace, optimized_grad, label='optimized_data')\n",
    "_ = axes[0].legend(), axes[1].legend()\n",
    "fig.savefig(os.path.join('./charts/', 'differentiability_illustration_gradient.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
